{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T11:44:25.5324Z",
          "iopub.execute_input": "2024-02-13T11:44:25.533243Z",
          "iopub.status.idle": "2024-02-13T11:44:25.537105Z",
          "shell.execute_reply.started": "2024-02-13T11:44:25.533213Z",
          "shell.execute_reply": "2024-02-13T11:44:25.536212Z"
        },
        "trusted": true,
        "id": "VwCD2Gc5jy3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T11:33:04.208298Z",
          "iopub.execute_input": "2024-02-13T11:33:04.208962Z",
          "iopub.status.idle": "2024-02-13T11:33:11.634852Z",
          "shell.execute_reply.started": "2024-02-13T11:33:04.20893Z",
          "shell.execute_reply": "2024-02-13T11:33:11.633815Z"
        },
        "trusted": true,
        "id": "83DrG6w6jy3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tokenizer_and_model(model_name_or_path):\n",
        "  return GPT2Tokenizer.from_pretrained(model_name_or_path), GPT2LMHeadModel.from_pretrained(model_name_or_path).cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T11:33:11.636362Z",
          "iopub.execute_input": "2024-02-13T11:33:11.636799Z",
          "iopub.status.idle": "2024-02-13T11:33:11.641296Z",
          "shell.execute_reply.started": "2024-02-13T11:33:11.636772Z",
          "shell.execute_reply": "2024-02-13T11:33:11.640429Z"
        },
        "trusted": true,
        "id": "HMXgO4IXjy3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "    model, tok, text,\n",
        "    do_sample=True, max_length=80, repetition_penalty=2.0,\n",
        "    top_k=5, top_p=0.95, temperature=1,\n",
        "    num_beams=None,\n",
        "    no_repeat_ngram_size=3\n",
        "    ):\n",
        "  input_ids = tok.encode(text, return_tensors=\"pt\").cuda()\n",
        "  out = model.generate(\n",
        "      input_ids.cuda(),\n",
        "      max_length=max_length,\n",
        "      repetition_penalty=repetition_penalty,\n",
        "      do_sample=do_sample,\n",
        "      top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "      num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size\n",
        "      )\n",
        "  return list(map(tok.decode, out))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T12:20:58.641669Z",
          "iopub.execute_input": "2024-02-13T12:20:58.642044Z",
          "iopub.status.idle": "2024-02-13T12:20:58.648701Z",
          "shell.execute_reply.started": "2024-02-13T12:20:58.642016Z",
          "shell.execute_reply": "2024-02-13T12:20:58.647798Z"
        },
        "trusted": true,
        "id": "iTbZaVU-jy3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok, model = load_tokenizer_and_model(\"sberbank-ai/rugpt2large\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T12:20:59.689735Z",
          "iopub.execute_input": "2024-02-13T12:20:59.690795Z",
          "iopub.status.idle": "2024-02-13T12:21:02.671895Z",
          "shell.execute_reply.started": "2024-02-13T12:20:59.690762Z",
          "shell.execute_reply": "2024-02-13T12:21:02.671103Z"
        },
        "trusted": true,
        "id": "pNUmIVdrjy3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "starters = ['\\nОктябрь уж наступил — уж роща отряхает\\nПоследние листы с нагих своих ветвей',\n",
        "           '\\nТот, кто любит цветы,\\nТот, естественно, пулям не нравится.',\n",
        "           '\\nЯ помню чудное мгновенье:\\nПередо мной явилась ты,',\n",
        "           '\\nЯ вас любил: любовь еще, быть может,\\nВ душе моей угасла не совсем,',\n",
        "           '\\nПечально я гляжу на наше поколенье!\\nЕго грядущее — иль пусто, иль темно,',\n",
        "           '\\nТы меня не любишь, не жалеешь,\\nРазве я немного не красив?',\n",
        "           '\\nПотонула деревня в ухабинах,\\nЗаслонили избенки леса.',\n",
        "           '\\nЖил-был поп,\\nТолоконный лоб.',\n",
        "           '\\nПродолговатый и твердый овал,\\nЧерного платья раструбы…',\n",
        "           '\\nЯ памятник себе воздвиг чудесный, вечный,\\nМеталлов тверже он и выше пирамид;']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T12:08:23.124084Z",
          "iopub.execute_input": "2024-02-13T12:08:23.124717Z",
          "iopub.status.idle": "2024-02-13T12:08:23.130298Z",
          "shell.execute_reply.started": "2024-02-13T12:08:23.124687Z",
          "shell.execute_reply": "2024-02-13T12:08:23.129365Z"
        },
        "trusted": true,
        "id": "c9Saf1wijy3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poems = []\n",
        "'''\n",
        "    do_sample=True, max_length=200, repetition_penalty=5.0,\n",
        "    top_k=5, top_p=0.95, temperature=1,\n",
        "    num_beams=None,\n",
        "    no_repeat_ngram_size=3\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T11:33:35.130597Z",
          "iopub.execute_input": "2024-02-13T11:33:35.131439Z",
          "iopub.status.idle": "2024-02-13T11:33:41.756015Z",
          "shell.execute_reply.started": "2024-02-13T11:33:35.131406Z",
          "shell.execute_reply": "2024-02-13T11:33:41.754824Z"
        },
        "trusted": true,
        "id": "kIEewAxPjy3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poems2 = []\n",
        "'''\n",
        "    do_sample=True, max_length=80, repetition_penalty=2.0,\n",
        "    top_k=5, top_p=0.95, temperature=1,\n",
        "    num_beams=None,\n",
        "    no_repeat_ngram_size=3\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T11:57:35.456802Z",
          "iopub.execute_input": "2024-02-13T11:57:35.457172Z",
          "iopub.status.idle": "2024-02-13T11:57:35.464353Z",
          "shell.execute_reply.started": "2024-02-13T11:57:35.457143Z",
          "shell.execute_reply": "2024-02-13T11:57:35.463455Z"
        },
        "trusted": true,
        "id": "vNAOkY-Wjy3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for starter in starters:\n",
        "    print(starter)\n",
        "    poem = generate(model, tok, starter, num_beams=10)[0]\n",
        "    poems.append(poem)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T12:21:11.537953Z",
          "iopub.execute_input": "2024-02-13T12:21:11.538313Z",
          "iopub.status.idle": "2024-02-13T12:22:24.522783Z",
          "shell.execute_reply.started": "2024-02-13T12:21:11.538285Z",
          "shell.execute_reply": "2024-02-13T12:22:24.521966Z"
        },
        "trusted": true,
        "id": "JC8Gf5fDjy3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}